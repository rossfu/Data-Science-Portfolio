#Create a classification model
#import the libraries you need

import org.apache.spark.sql.types._
import org.apache.spark.sql.functions._

import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.feature.VectorAssembler

#Load Source Data

val csv = spark.read.option("inferSchema","true").option("header", "true").csv("wasb:///data/flights.csv")
csv.show()

#Prepare the Data

val data = csv.select($"DayofMonth", $"DayOfWeek", $"OriginAirportID", $"DestAirportID", $"DepDelay", ($"ArrDelay" > 15).cast("Int").alias("Late"))
data.show()

#Split the Data

val splits = data.randomSplit(Array(0.7, 0.3))
val train = splits(0)
val test = splits(1)
val train_rows = train.count()
val test_rows = test.count()
println("Training Rows: " + train_rows + " Testing Rows: " + test_rows)

#Prepare the Training Data

val assembler = new VectorAssembler().setInputCols(Array("DayofMonth", "DayOfWeek", "OriginAirportID", "DestAirportID", "DepDelay")).setOutputCol("features")
val training = assembler.transform(train).select($"features", $"Late".alias("label"))
training.show()

#Train a Classification Model

val lr = new LogisticRegression().setLabelCol("label").setFeaturesCol("features").setMaxIter(10).setRegParam(0.3)
val model = lr.fit(training)
println ("Model trained!")

#Prepare the Testing Data

val testing = assembler.transform(test).select($"features", $"Late".alias("trueLabel"))
testing.show()

#Test Model

val prediction = model.transform(testing)
val predicted = prediction.select("features", "prediction", "probability", "trueLabel")
predicted.show(100)
